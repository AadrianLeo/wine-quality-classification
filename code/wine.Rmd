---
title: "Wine Quality Analysis and Data Preparation"
author: "Wine Quality Project Group"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE
)

library(here)
library(dplyr)
library(tidyr)
library(ggplot2)
library(corrplot)
```

# Introduction

This report prepares and explores the red wine quality dataset. The goals are to:

- Load the raw data from the project `data` folder.
- Perform initial exploratory data analysis (EDA).
- Engineer a binary target variable ("Poor" vs. "Premium" wines).
- Save a cleaned version of the dataset for modeling.

# Load the Data

```{r load-data}
# Path to the dataset (red wine quality)
data_path <- here("data/winequality-red.csv")
# Load the dataset
wine <- read.csv2(data_path)

## Basic structure and sanity checks
dim(wine)
str(wine)
nrow(wine)
ncol(wine)
summary(wine)
head(wine)
```
We first check for missing values and the distribution of the original quality scores.
```{r missing-and-distribution}
# Check missing values per column
colSums(is.na(wine))

# Distribution of original quality scores
table(wine$quality)
prop.table(table(wine$quality))
```

```{r hist-quality}
hist(
	wine$quality,
	main = "Distribution of Wine Quality Scores",
	xlab = "Quality",
	col = "lightblue",
	breaks = 10
)
```

# Data Exploration

We ensure that key variables are treated as numeric and visually compare alcohol content across quality scores.
```{r ensure-numeric}
wine$quality <- as.numeric(as.character(wine$quality))
wine$alcohol <- as.numeric(wine$alcohol)
str(wine[, c("quality", "alcohol")])
```

```{r boxplot-alcohol-quality}
boxplot(
	alcohol ~ quality,
	data = wine,
	main = "Alcohol Content vs Wine Quality",
	xlab = "Quality",
	ylab = "Alcohol"
)
```


For some analyses, it is useful to keep the original quality as a factor.

```{r quality-factor}
wine$quality_factor <- as.factor(wine$quality)
str(wine)
str(wine$quality_factor)
```

# Target Engineering and Cleaning
We now create a binary classification target:

- `Premium` (1): quality \(\geq 7\)
- `Poor` (0): quality \(\leq 6\)
```{r target-binary}
wine$quality_binary <- ifelse(wine$quality >= 7, 1, 0)

wine$quality_binary <- factor(
	wine$quality_binary,
	levels = c(0, 1),
	labels = c("Poor", "Premium")
)

table(wine$quality_binary)
prop.table(table(wine$quality_binary))
```

We remove the original numeric `quality` variable to avoid redundancy in the cleaned dataset.
```{r checks-clean}
wine_clean <- wine
wine_clean$quality <- NULL

numeric_cols <- c(
  "fixed.acidity", "volatile.acidity", "citric.acid",
  "residual.sugar", "chlorides",
  "free.sulfur.dioxide", "total.sulfur.dioxide",
  "density", "pH", "sulphates", "alcohol"
)

wine_clean[numeric_cols] <- lapply(wine_clean[numeric_cols], as.numeric)
str(wine_clean)
summary(wine_clean)


```


# Save Cleaned Dataset
Finally, we save the cleaned red wine dataset into the `data` folder so it can be reused for modeling.
```{r save-cleaned}
dir.create(here("data"), showWarnings = FALSE)

# Save cleaned wine dataset
write.csv(
  wine_clean,
  here("data", "winequality-red-clean.csv"),
  row.names = FALSE
)
```
# Checking Cleaned Dataset

For reference, we compare basic summaries after cleaning.
```{r check-cleaned}
colSums(is.na(wine_clean))

sum(duplicated(wine_clean))

str(wine_clean)

boxplot(
  wine_clean$alcohol,
  main = "Boxplot of Alcohol (Outlier Check)",
  ylab = "Alcohol"
)

dim(wine)        # original

dim(wine_clean)  # cleaned

summary(wine)
summary(wine_clean)

table(wine$quality)

table(wine_clean$quality_binary)
prop.table(table(wine_clean$quality_binary))

duplicate_rows <- wine_clean[duplicated(wine_clean), ]
nrow(duplicate_rows)
head(duplicate_rows)
which(duplicated(wine_clean))


head(wine_clean)
```



# EDA
## Distribution of Wine Quality
```{r}
library(ggplot2)
ggplot(wine_clean, aes(x = quality_binary)) +
  geom_bar(fill = "orange") +
  ggtitle("Distribution of Wine Quality") +
  xlab("Quality") + ylab("Count")
```

The bar chart above illustrates the distribution of the target variable `quality_binary`.  
The dataset shows a clear class imbalance, with the majority of observations belonging to the *Poor* quality category. Out of 1,599 wine samples, approximately **86% (1,382 wines)** are classified as *Poor*, while only **14% (217 wines)** are categorized as *Premium*. This indicates that Premium-quality wines occur far less frequently in the dataset compared to Poor-quality wines.


## Correlation Analysis of Numeric Features
```{r}
library(corrplot)

#Pairplot / Correlation plot
library(corrplot)
cor_mat <- cor(wine_clean[, numeric_cols])
corrplot(cor_mat, method = "color", type = "upper")
```


The correlation heatmap shows the pairwise relationships among numeric features in the wine dataset.

- **High positive correlations** are observed between **density and fixed acidity**, and between **citric acid and fixed acidity**, suggesting that wines with higher fixed acidity also tend to have higher density and citric acid content. 

- **Negative correlations** are seen between **pH and fixed acidity**, and **alcohol and density**, indicating that wines with higher fixed acidity have lower pH, and higher alcohol content is associated with lower density.  

- Some features show **very weak or negligible correlations**, such as **alcohol versus citric acid** and **alcohol versus fixed acidity**, implying that these variables are largely independent of each other.  

These relationships help identify which variables are related and which are not, providing insights for feature selection and further analysis.




## Density vs Fixed Acidity

```{r}
par(mfrow = c(2, 3)) 
r1 <- round(cor(wine_clean$`fixed.acidity`, wine_clean$density), 2)
plot(wine_clean$`fixed.acidity`, wine_clean$density,
     main = paste("Density vs Fixed Acidity (r =", r1, ")"),
     xlab = "Fixed Acidity", ylab = "Density",
     col = "steelblue", pch = 16)

# Citric Acid vs Fixed Acidity
r2 <- round(cor(wine_clean$`fixed.acidity`, wine_clean$`citric.acid`), 2)
plot(wine_clean$`fixed.acidity`, wine_clean$`citric.acid`,
     main = paste("Citric Acid vs Fixed Acidity (r =", r2, ")"),
     xlab = "Fixed Acidity", ylab = "Citric Acid",
     col = "steelblue", pch = 16)

# pH vs Fixed Acidity
r3 <- round(cor(wine_clean$`fixed.acidity`, wine_clean$pH), 2)
plot(wine_clean$`fixed.acidity`, wine_clean$pH,
     main = paste("pH vs Fixed Acidity (r =", r3, ")"),
     xlab = "Fixed Acidity", ylab = "pH",
     col = "brown", pch = 16)

# Alcohol vs Density
r4 <- round(cor(wine_clean$density, wine_clean$alcohol), 2)
plot(wine_clean$density, wine_clean$alcohol,
     main = paste("Alcohol vs Density (r =", r4, ")"),
     xlab = "Density", ylab = "Alcohol",
     col = "brown", pch = 16)

# Alcohol vs Fixed Acidity
r5 <- round(cor(wine_clean$`fixed.acidity`, wine_clean$alcohol), 2)
plot(wine_clean$`fixed.acidity`, wine_clean$alcohol,
     main = paste("Alcohol vs Fixed Acidity (r =", r5, ")"),
     xlab = "Fixed Acidity", ylab = "Alcohol",
     col = "pink", pch = 16)

# Alcohol vs Citric Acid
r6 <- round(cor(wine_clean$`citric.acid`, wine_clean$alcohol), 2)
plot(wine_clean$`citric.acid`, wine_clean$alcohol,
     main = paste("Alcohol vs Citric Acid (r =", r6, ")"),
     xlab = "Citric Acid", ylab = "Alcohol",
     col = "pink", pch = 16)


par(mfrow = c(1, 1))  
```

- **Density vs Fixed Acidity (r = 0.67)** and **Citric Acid vs Fixed Acidity (r = 0.67)** show moderate-to-strong positive correlations, meaning that as Fixed Acidity increases, Density and Citric Acid also increase.

- **pH vs Fixed Acidity (r = -0.68)** and **Alcohol vs Density (r = -0.5)** show negative correlations, meaning that as Fixed Acidity increases, pH decreases, and higher Alcohol content tends to lower Density.

- where as **Alcohol vs Fixed Acidity** **(r = -0.06) and Alcohol vs Citric Acid (r = 0.11)** show negligible correlations.

Fixed acidity in wine has a strong influence on its density, citric acid content, and pH. Higher levels of fixed acidity tend to increase density and citric acid while lowering pH, which aligns chemically with the expected inverse relationship between acidity and pH. In contrast, alcohol content shows a somewhat inverse relationship with density but appears largely independent of fixed acidity and citric acid. These patterns are consistent with the chemical properties of wine, where acids contribute to its overall density and acidity naturally reduces pH.


## pH distribution

```{r}
hist(wine_clean$pH,
     main = "Distribution of pH in Red Wine",
     xlab = "pH",
     col = "lightblue",
     border = "black",
     breaks = 15)  # number of bins
```

- The histogram shows that the pH values of red wine are approximately normally distributed, with most observations  **concentrated between pH 3.1 and 3.4 ** and a **clear peak around pH 3.3 **. Since pH indicates how acidic the wine is, with (lower pH values = higher acidity), this distribution suggests that most red wines in the dataset have a moderate and well-balanced level of acidity.Such balanced acidity is important for good taste, color stability, and preservation.

- **Very low pH values below 3.0 and high pH values above 3.7 occur infrequently **, indicating that extreme acidity levels are rare. The small number of wines with higher pH values on the right side of the distribution are less acidic and relatively uncommon, while the close clustering of values overall suggests that the wine-making process is fairly consistent across samples.



## Alcohol distribution

```{r}
hist(wine_clean$alcohol,
     main = "Distribution of Alcohol Content",
     xlab = "Alcohol (%)",
     col = "lightgreen",
     border = "black",
     breaks = 15)
```

- The histogram shows the distribution of alcohol content in red wine, which is slightly right-skewed. 
Most wines have alcohol levels concentrated between about **9% and 11%**, with a **clear peak around 9.5–10%**, indicating that the **majority of samples have moderate alcohol content**. Lower alcohol values below 9% and higher values above 12% occur much less frequently, suggesting that extreme alcohol levels are uncommon. The long tail toward higher alcohol percentages shows that a smaller number of wines have relatively high alcohol content, reaching up to around 14–15%.

- Overall it shows that, most wines have moderate alcohol content, with only a few unusually low or high.

## Pie chart of quality_factor 

```{r}
q_table <- table(wine_clean$quality_factor)
q_percent <- round(prop.table(q_table) * 100, 1)
labels <- paste(names(q_table), "-", q_percent, "%")


pie(q_table,
    labels = labels,
    main = "Wine Quality Score Distribution",
    col = rainbow(length(q_table)))
```
- The pie chart illustrates the distribution of wine quality scores in the dataset. Most wines fall into the **medium quality range, with quality scores of 5 (42.6%) and 6 (39.9%)**, together accounting for the large majority of samples. This indicates that the dataset is dominated by average-quality wines. A smaller proportion of wines have higher quality scores, with **score 7 representing about 12.4%**, suggesting that good-quality wines are less common. 
- **Very low and very high quality scores are rare**, as shown by the small percentages for scores **3 (0.6%), 4 (3.3%), and 8 (1.1%).** Overall, the distribution suggests that most wines are of moderate quality, with relatively few exceptional or poor-quality samples.




## Groupby Quality vs other columns

```{r}
cols <- c("fixed.acidity", "volatile.acidity", "citric.acid",
          "residual.sugar", "chlorides", "free.sulfur.dioxide",
          "total.sulfur.dioxide", "density", "pH",
          "sulphates", "alcohol")


agg_df <- wine_clean %>%
  group_by(quality_factor) %>%
  summarise(
    across(all_of(cols), mean, na.rm = TRUE),
    .groups = "drop"
  )

agg_long <- agg_df %>%
  pivot_longer(
    cols = all_of(cols),
    names_to = "Variable",
    values_to = "Frequency"
  )

ggplot(
  agg_long,
  aes(
    x = factor(quality_factor),
    y = Frequency,
    fill = Variable
  )
) +
  geom_bar(
    stat = "identity",
    position = "dodge"
  ) +
  
  
  scale_fill_manual(values = c(
    "fixed.acidity" = "steelblue",
    "volatile.acidity" = "orange",
    "citric.acid" = "green",
    "residual.sugar" = "red",
    "chlorides" = "purple",
    "free.sulfur.dioxide" = "brown",
    "total.sulfur.dioxide" = "pink",
    "density" = "grey",
    "pH" = "yellow",
    "sulphates" = "cyan",
    "alcohol" = "darkblue"
  )) +
  
  
  labs(
    title = "Grouped Bar Chart of Chemical Variables by Wine Quality",
    x = "Quality Factor",
    y = "Total Frequency / Amount"
  ) +
  theme_minimal() +
  theme(
    legend.position = "top",
    axis.text.x = element_text(size = 11),
    axis.title = element_text(size = 12),
    plot.title = element_text(size = 14, face = "bold")
  )
```

From the grouped bar chart, we observe that Other variables like **chlorides, citric acid, density, sulphates, and volatile acidity** have lower average values and stay fairly stable across quality levels, suggesting they have a smaller impact on wine quality also **alcohol slightly increases as quality increases in 6,7,8 **. However, total sulfur dioxide shows a notable **peak at quality factor 5**, **slightly lower in 6, and decreases further in both lower and higher quality wines**. This suggests that medium-quality wines may require higher sulfur dioxide content, while higher-quality wines appear to use less, possibly due to better natural preservation and processing techniques.


- **Essential for preservation:** Sulfur dioxide prevents oxidation and microbial spoilage, keeping wine stable and extending shelf life.

- **Moderate amounts are beneficial:** Moderate SO₂ protects flavors and prevents undesirable changes during aging.

- **Excessive amounts can harm quality:** Too much SO₂ can cause off-aromas, harsher taste, and lower perceived quality.

- **Low sensory threshold:** Humans can detect sulfur at very low levels, so small increases can affect aroma and taste.

The observed peak in total sulfur dioxide at quality factor 5 suggests that these wines require more chemical preservation, possibly due to lower natural stability or simpler winemaking processes. In contrast, higher-quality wines (6–8) use less sulfur dioxide, implying better natural quality and less reliance on additives. This aligns with wine science, which indicates that while sulphur dioxide is essential for wine preservation, excessive amounts can negatively influence taste and perceived quality.


## Box plot of quality factor vs alcohol

```{r}
boxplot(alcohol ~ quality_factor,
        data = wine_clean,
        main = "Alcohol Content by Wine Quality",
        xlab = "Wine Quality Score",
        ylab = "Alcohol (%)",
        col = "lightblue")
```

- The boxplot shows an increasing trend in alcohol content with rising wine quality, suggesting a **positive relationship between alcohol percentage and wine quality**. Quality factors **5 and 6 display a higher number of outliers**. These outliers indicate that alcohol content alone does not fully determine wine quality, as wines with unusually high or low alcohol levels can still receive similar quality scores.

- When considering the **earlier visualization of total sulfur dioxide alongside the quality–alcohol** relationship, it becomes evident that wine quality is influenced by multiple interacting factors. **Higher alcohol content alone does not guarantee better quality**, as other components such as sulfur dioxide can negatively affect sensory perception when present in excess.








<!-- wine$quality_factor <- as.factor(wine$quality) -->

# Mathematical Overview of Methods (ML1 + ML2)

This section briefly summarizes the mathematical foundations of the two machine learning methods used in this project: **Logistic Regression (ML1)** and **Support Vector Machines with a Radial (RBF) kernel (ML2)**. The focus is on the key equations, decision rules, and the meaning of the main hyperparameters.

## Logistic Regression (ML1)

Logistic Regression is a probabilistic classification model that directly models the conditional probability of the positive class (here: **Premium**) given an input feature vector \(x \in \mathbb{R}^p\). Let \(Y \in \{0,1\}\) denote the class label (0 = Poor, 1 = Premium). Logistic regression assumes that the **log-odds** of the positive class are a linear function of the predictors:

\[
\log\left(\frac{P(Y=1\mid x)}{1-P(Y=1\mid x)}\right) = \beta_0 + \beta^T x
\]

Applying the inverse logit (sigmoid) function gives the predicted probability:

\[
P(Y=1\mid x) = \sigma(\beta_0 + \beta^T x)
           = \frac{1}{1+\exp\left(-(\beta_0 + \beta^T x)\right)}
\]

The parameters \(\beta_0, \beta\) are estimated via **maximum likelihood estimation (MLE)**. For \(n\) observations \(\{(x_i,y_i)\}_{i=1}^n\), the likelihood is:

\[
L(\beta) = \prod_{i=1}^n p_i^{y_i}(1-p_i)^{1-y_i},
\quad \text{where } p_i = P(Y=1\mid x_i)
\]

Equivalently, one maximizes the log-likelihood:

\[
\ell(\beta) = \sum_{i=1}^n \left[y_i\log(p_i) + (1-y_i)\log(1-p_i)\right]
\]

To obtain class predictions, a decision threshold \(t \in (0,1)\) is chosen:

\[
\hat{y}=
\begin{cases}
1 & \text{if } \hat{p} \ge t \\
0 & \text{if } \hat{p} < t
\end{cases}
\]

Because the dataset is imbalanced, using \(t=0.5\) is not always optimal; therefore, the threshold can be selected on the validation set using a criterion such as **Youden’s J** from the ROC curve.

---

## Support Vector Machine with RBF Kernel (ML2)

Support Vector Machines (SVMs) are margin-based classifiers. In the linearly separable case, the goal is to find a hyperplane

\[
f(x) = w^T x + b
\]

that separates the classes while maximizing the **margin**, i.e., the distance between the hyperplane and the closest training points (the **support vectors**). In practice, perfect separation is rarely possible, so SVMs use the **soft-margin** formulation with slack variables \(\xi_i\), controlled by the hyperparameter \(C>0\):

\[
\min_{w,b,\xi}\;\;\frac{1}{2}\|w\|^2 + C\sum_{i=1}^n \xi_i
\]
subject to
\[
y_i(w^T x_i + b) \ge 1 - \xi_i,\quad \xi_i \ge 0,\;\; i=1,\dots,n
\]

The parameter \(C\) determines the trade-off between:
- **large margin** (simpler decision boundary, more regularization) and
- **classification errors** on the training set (less regularization).

If the data are not linearly separable in the original feature space, SVMs can use a **kernel function** \(K(x,x')\) to represent a nonlinear decision boundary implicitly. In this project, we use the **Radial Basis Function (RBF) kernel**:

\[
K(x,x') = \exp\left(-\gamma \|x-x'\|^2\right)
\]

In `caret::svmRadial`, this is often parameterized using \(\sigma\), where typically \(\gamma\) is related to \(\sigma\) (depending on implementation) and controls how quickly similarity decays with distance. Intuitively:

- **Large \(\gamma\)** (small \(\sigma\)) → very flexible, highly nonlinear boundary (risk of overfitting)  
- **Small \(\gamma\)** (large \(\sigma\)) → smoother boundary (risk of underfitting)

Thus, for RBF-SVM we tune:
- \(C\): penalty for misclassification (margin vs errors)
- \(\sigma\) (or \(\gamma\)): kernel width (complexity / smoothness)

Since SVM relies on distances, it is **sensitive to feature scaling**, so predictors should be standardized (centered and scaled) before training.

---

**Summary:** Logistic Regression is a linear probabilistic classifier based on log-odds and maximum likelihood estimation, while RBF-SVM is a margin-based method that can create nonlinear decision boundaries through the kernel trick. Both methods output scores/probabilities that can be converted into class labels using a threshold chosen on the validation set, which is especially important under


# Predictor variables will be standardized before training SVM, as SVM is sensitive to feature scaling The dataset shows a strong class imbalance, therefore performance evaluation will rely on ROC-AUC and F1-score rather than accuracy alone.

```{r}
wine_model <- wine_clean
wine_model$quality_factor <- NULL
```


# Data Split for Modeling (Train / Validation / Test)

```{r}
library(caret)

set.seed(42)

idx_train <- createDataPartition(wine_model$quality_binary, p = 0.60, list = FALSE)
train <- wine_model[idx_train, ]
temp  <- wine_model[-idx_train, ]

idx_valid <- createDataPartition(temp$quality_binary, p = 0.50, list = FALSE)
valid <- temp[idx_valid, ]
test  <- temp[-idx_valid, ]

dir.create(here("data"), showWarnings = FALSE)

write.csv(train, here("data", "wine_train.csv"), row.names = FALSE)
write.csv(valid, here("data", "wine_valid.csv"), row.names = FALSE)
write.csv(test,  here("data", "wine_test.csv"),  row.names = FALSE)

prop.table(table(train$quality_binary))
prop.table(table(valid$quality_binary))
prop.table(table(test$quality_binary))
```


# ML1: Logistic Regression

```{r}
library(pROC)
```

## Fit Logistic Regression (Train Set)

```{r}
logit_model <- glm(quality_binary ~ ., data = train, family = binomial)
summary(logit_model)
```

## Odds Ratios

```{r}
odds_ratios <- exp(coef(logit_model))
odds_ratios

or_ci <- exp(cbind(OR = coef(logit_model), confint(logit_model)))
or_ci
```

## Validation: Predict Probabilities

```{r}
valid_prob <- predict(logit_model, newdata = valid, type = "response")
head(valid_prob)
```

## Validation: ROC & AUC

```{r}
roc_valid <- roc(
  response = valid$quality_binary,
  predictor = valid_prob,
  levels = c("Poor", "Premium"),
  direction = "<"
)

plot(roc_valid, col = "darkgreen", main = "ROC Curve - Logistic Regression (Validation Set)")
auc(roc_valid)
```

## Validation: Choose Threshold (Youden)

```{r}
best_valid <- coords(
  roc_valid,
  "best",
  ret = c("threshold", "sensitivity", "specificity"),
  best.method = "youden"
)
best_valid
```

## Validation: Confusion Matrix (Default 0.5 vs Best Threshold)

```{r}
# Default threshold
pred_valid_05 <- ifelse(valid_prob >= 0.5, "Premium", "Poor")
pred_valid_05 <- factor(pred_valid_05, levels = c("Poor", "Premium"))

cm_valid_05 <- confusionMatrix(pred_valid_05, valid$quality_binary, positive = "Premium")
cm_valid_05

# Best threshold from ROC
best_thr <- as.numeric(best_valid["threshold"])

pred_valid_best <- ifelse(valid_prob >= best_thr, "Premium", "Poor")
pred_valid_best <- factor(pred_valid_best, levels = c("Poor", "Premium"))

cm_valid_best <- confusionMatrix(pred_valid_best, valid$quality_binary, positive = "Premium")
cm_valid_best
```

## Final Test Evaluation (Use Test Only Once)

```{r}
test_prob <- predict(logit_model, newdata = test, type = "response")

test_pred <- ifelse(test_prob >= best_thr, "Premium", "Poor")
test_pred <- factor(test_pred, levels = c("Poor", "Premium"))

cm_test <- confusionMatrix(test_pred, test$quality_binary, positive = "Premium")
cm_test
```

## Test: ROC & AUC

```{r}
roc_test <- roc(
  response = test$quality_binary,
  predictor = test_prob,
  levels = c("Poor", "Premium"),
  direction = "<"
)

plot(roc_test, col = "blue", main = "ROC Curve - Logistic Regression (Test Set)")
auc(roc_test)
```


# ML2: Support Vector Machine (SVM) Model (Wine Quality)

```{r setup_svm, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
set.seed(123)
```

## Packages

```{r packages_svm}
# If needed, install packages once in the R console, e.g.:
# install.packages(c("here","caret","pROC","dplyr","kernlab"))

library(here)
library(caret)
library(pROC)
library(dplyr)
library(kernlab)  # required for svmRadial in caret
```

## Fit SVM (Radial) Model

```{r fit-svm}
# 3) Fit SVM (Radial) with CV tuning on TRAIN only
# SVM is sensitive to scaling -> preProcess centers/scales predictors
ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  savePredictions = "final"
)

svm_grid <- expand.grid(
  sigma = c(0.005, 0.01, 0.02, 0.05),
  C     = c(0.5, 1, 2, 5, 10)
)

svm_model <- train(
  quality_binary ~ .,
  data = train,
  method = "svmRadial",
  preProcess = c("center", "scale"),
  metric = "ROC",
  trControl = ctrl,
  tuneGrid = svm_grid
)

svm_model
svm_model$bestTune
```

## Predict Probabilities

```{r predict-prob}
# 4) Predict probabilities
svm_valid_prob <- predict(svm_model, newdata = valid, type = "prob")[, "Premium"]
svm_test_prob  <- predict(svm_model, newdata = test,  type = "prob")[, "Premium"]

```

## Choose Threshold (Validation Set)

```{r choose-threshold}
# 5) Choose threshold using Validation set (Youden's J from ROC)
svm_roc_valid <- roc(
  response = valid$quality_binary,
  predictor = svm_valid_prob,
  levels = c("Poor","Premium"),
  direction = "<"
)

best <- coords(
  svm_roc_valid,
  x = "best",
  best.method = "youden",
  transpose = FALSE
)

best_thresh <- as.numeric(best["threshold"])
best_thresh

```

## Class Predictions

```{r class-predictions}
# 6) Class predictions using chosen threshold
valid_pred <- factor(ifelse(svm_valid_prob >= best_thresh, "Premium", "Poor"),
                     levels = c("Poor","Premium"))

test_pred  <- factor(ifelse(svm_test_prob >= best_thresh, "Premium", "Poor"),
                     levels = c("Poor","Premium"))

```

## Model Evaluation

```{r eval-valid}
# 7) Evaluation (Validation)
confusionMatrix(valid_pred, valid$quality_binary, positive = "Premium")

svm_auc_valid <- auc(svm_roc_valid)
svm_auc_valid

```

```{r eval-test}
# 8) Final Evaluation (TEST ONLY)
svm_roc_test <- roc(
  response = test$quality_binary,
  predictor = svm_test_prob,
  levels = c("Poor","Premium"),
  direction = "<"
)

svm_auc_test <- auc(svm_roc_test)
svm_auc_test

confusionMatrix(test_pred, test$quality_binary, positive = "Premium")

```

## ROC Plot (Test Set)

```{r roc-plot}
# 9) Optional: ROC plot (test)
plot(svm_roc_test, main = "SVM (Radial) ROC (Test Set)")
```


