---
title: "ML1 - Logistic Regression (Red Wine Quality)"
output:
  html_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE
)
```

## Libraries

```{r}
library(caret)
library(pROC)
```

## Load Data

```{r}
df <- read.csv("../data/winequality-red-clean.csv", stringsAsFactors = FALSE)
```

## Basic Checks

```{r}
str(df)
head(df, 3)
```

## Target & Feature Preparation

```{r}
# Target must exist
if (!("quality_binary" %in% names(df))) stop("'quality_binary' column not found in dataset.")

# Set positive class as Premium
df$quality_binary <- factor(df$quality_binary, levels = c("Poor", "Premium"))

# Drop label-like column (potential leakage)
if ("quality_factor" %in% names(df)) {
  df$quality_factor <- NULL
}

# Convert predictors to numeric
predictor_cols <- setdiff(names(df), "quality_binary")
df[predictor_cols] <- lapply(df[predictor_cols], function(x) as.numeric(x))

# Remove any rows with NA after conversion
df <- na.omit(df)

# Class balance
table(df$quality_binary)
prop.table(table(df$quality_binary))
```

## Train / Validation / Test Split (60/20/20)

```{r}
set.seed(42)

# 60% train, 40% temp
idx_train <- createDataPartition(df$quality_binary, p = 0.60, list = FALSE)
train <- df[idx_train, ]
temp  <- df[-idx_train, ]

# split temp equally into validation and test (20/20)
idx_valid <- createDataPartition(temp$quality_binary, p = 0.50, list = FALSE)
valid <- temp[idx_valid, ]
test  <- temp[-idx_valid, ]

# Verify class proportions
prop.table(table(train$quality_binary))
prop.table(table(valid$quality_binary))
prop.table(table(test$quality_binary))
```

## Fit Logistic Regression (Train Set)

```{r}
logit_model <- glm(quality_binary ~ ., data = train, family = binomial)
summary(logit_model)
```

## Odds Ratios

```{r}
odds_ratios <- exp(coef(logit_model))
odds_ratios

or_ci <- exp(cbind(OR = coef(logit_model), confint(logit_model)))
or_ci
```

## Validation: Predict Probabilities

```{r}
valid_prob <- predict(logit_model, newdata = valid, type = "response")
head(valid_prob)
```

## Validation: ROC & AUC

```{r}
roc_valid <- roc(
  response = valid$quality_binary,
  predictor = valid_prob,
  levels = c("Poor", "Premium"),
  direction = "<"
)

plot(roc_valid, col = "darkgreen", main = "ROC Curve - Logistic Regression (Validation Set)")
auc(roc_valid)
```

## Validation: Choose Threshold (Youden)

```{r}
best_valid <- coords(
  roc_valid,
  "best",
  ret = c("threshold", "sensitivity", "specificity"),
  best.method = "youden"
)
best_valid
```

## Validation: Confusion Matrix (Default 0.5 vs Best Threshold)

```{r}
# Default threshold
pred_valid_05 <- ifelse(valid_prob >= 0.5, "Premium", "Poor")
pred_valid_05 <- factor(pred_valid_05, levels = c("Poor", "Premium"))

cm_valid_05 <- confusionMatrix(pred_valid_05, valid$quality_binary, positive = "Premium")
cm_valid_05

# Best threshold from ROC
best_thr <- as.numeric(best_valid["threshold"])

pred_valid_best <- ifelse(valid_prob >= best_thr, "Premium", "Poor")
pred_valid_best <- factor(pred_valid_best, levels = c("Poor", "Premium"))

cm_valid_best <- confusionMatrix(pred_valid_best, valid$quality_binary, positive = "Premium")
cm_valid_best
```

## Final Test Evaluation (Use Test Only Once)

```{r}
test_prob <- predict(logit_model, newdata = test, type = "response")

# Use the chosen threshold from validation (best_thr)
test_pred <- ifelse(test_prob >= best_thr, "Premium", "Poor")
test_pred <- factor(test_pred, levels = c("Poor", "Premium"))

cm_test <- confusionMatrix(test_pred, test$quality_binary, positive = "Premium")
cm_test
```

## Test: ROC & AUC

```{r}
roc_test <- roc(
  response = test$quality_binary,
  predictor = test_prob,
  levels = c("Poor", "Premium"),
  direction = "<"
)

plot(roc_test, col = "blue", main = "ROC Curve - Logistic Regression (Test Set)")
auc(roc_test)
```